{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## Simple Generator Model With the UpSampling2D Layer\n", 
        "The UpSampling2D layer is simple and effective, although does not perform any learning. It\n", 
        "is not able to fill in useful detail in the upsampling operation. To be useful in a GAN, each\n", 
        "UpSampling2D layer must be followed by a Conv2D layer that will learn to interpret the doubled\n", 
        "input and be trained to translate it into meaningful detail. We can demonstrate this with an\n", 
        "example.\n", 
        "In this example, our little GAN generator model must produce a 10 \u00d7 10 image as output\n", 
        "and take a 100 element vector of random numbers from the latent space as input. First, a Dense\n", 
        "fully connected layer can be used to interpret the input vector and create a sufficient number of\n", 
        "activations (outputs) that can be reshaped into a low-resolution version of our output image, in\n", 
        "this case, 128 versions of a 5 \u00d7 5 image."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of using upsampling in a simple generator model\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Reshape\n", 
        "from keras.layers import UpSampling2D\n", 
        "from keras.layers import Conv2D\n", 
        "# define model\n", 
        "model = Sequential()\n", 
        "# define input shape, output enough activations for for 128 5x5 image\n", 
        "model.add(Dense(128 * 5 * 5, input_dim=100))\n", 
        "# reshape vector of activations into 128 feature maps with 5x5\n", 
        "model.add(Reshape((5, 5, 128)))\n", 
        "# double input from 128 5x5 to 1 10x10 feature map\n", 
        "model.add(UpSampling2D())"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Finally, the upsampled feature maps can be interpreted and filled in with hopefully useful\n", 
        "detail by a Conv2D layer. The Conv2D has a single feature map as output to create the single\n", 
        "image we require."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# fill in detail in the upsampled feature maps and output a single image\n", 
        "model.add(Conv2D(1, (3,3), padding='same'))\n", 
        "# summarize model\n", 
        "model.summary()\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Running the example creates the model and summarizes the output shape of each layer. We\n", 
        "can see that the Dense layer outputs 3,200 activations that are then reshaped into 128 feature\n", 
        "maps with the shape 5\u00d75. The widths and heights are doubled to 10\u00d710 by the UpSampling2D\n", 
        "layer, resulting in a feature map with quadruple the area. Finally, the Conv2D processes these\n", 
        "feature maps and adds in detail, outputting a single 10 \u00d7 10 image"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}