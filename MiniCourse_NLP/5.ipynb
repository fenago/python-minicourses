{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "from keras.preprocessing.text import Tokenizer\n", 
        "# define 5 documents\n", 
        "docs = ['Well done!',\n", 
        "\t\t'Good work',\n", 
        "\t\t'Great effort',\n", 
        "\t\t'nice work',\n", 
        "\t\t'Excellent!']\n", 
        "# create the tokenizer\n", 
        "t = Tokenizer()\n", 
        "# fit the tokenizer on the documents\n", 
        "t.fit_on_texts(docs)\n", 
        "# summarize what was learned\n", 
        "print(t.word_counts)\n", 
        "print(t.document_count)\n", 
        "print(t.word_index)\n", 
        "print(t.word_docs)\n", 
        "# integer encode documents\n", 
        "encoded_docs = t.texts_to_matrix(docs, mode='count')\n", 
        "print(encoded_docs)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}